{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coffeepedia Data Cleaning Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "import json\n",
    "from json import dumps\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load two CSV files--coffee commodity data from the USDA Foreign Agricultural Service (https://apps.fas.usda.gov/psdonline/app/index.html) and geographical coordinate data from Harvard University's WorldMap (https://worldmap.harvard.edu/data/geonode:country_centroids_az8).  We will then remove any extraneous columns, rename columns to create a common column for merging, and renaming any values to ensure all countries will be mapped to geocoordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coffee commodity data\n",
    "coffee = pd.read_csv(\"psd_coffee.csv\")\n",
    "\n",
    "# country latitude/longitude data\n",
    "centroids = pd.read_csv(\"country_centroids_az8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce columns to only country name, latitude, longitude\n",
    "latlong = centroids[[\"geounit\", \"Latitude\", \"Longitude\"]]\n",
    "\n",
    "# rename country name column to match column name on coffee df\n",
    "latlong = latlong.rename(columns={\"geounit\":\"Country_Name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename countries to match all lat/long values\n",
    "# coffee csv contains european country info for \"European Union\" as a group only\n",
    "# so we must map the most geographically central country of the continent to the \"EU\" values\n",
    "coffee[\"Country_Name\"] = coffee[\"Country_Name\"].replace({\"Korea, South\": \"South Korea\",\n",
    "                                                         \"Congo (Brazzaville)\": \"Republic of Congo\",\n",
    "                                                         \"Congo (Kinshasa)\": \"Democratic Republic of the Congo\",\n",
    "                                                         \"Cote d'Ivoire\": \"Ivory Coast\",\n",
    "                                                         \"New Caledonia\": \"New Caledonia\",\n",
    "                                                         \"Serbia\": \"Republic of Serbia\",\n",
    "                                                         \"Yemen (Sanaa)\": \"Yemen\",\n",
    "                                                         \"United States\": \"United States of America\"\n",
    "                                                        })\n",
    "# now change \"Czech Republic\" back to \"European Union\"\n",
    "latlong[\"Country_Name\"] = latlong[\"Country_Name\"].replace({\"Czech Republic\": \"European Union\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge lat/long onto coffee df\n",
    "coffee_latlong = pd.merge(coffee, latlong, on=\"Country_Name\", how=\"left\")\n",
    "\n",
    "# remove extraneous columns\n",
    "coffee_latlong_min = coffee_latlong[[\"Country_Name\", \"Market_Year\", \"Attribute_Description\", \"Value\", \"Latitude\", \"Longitude\"]]\n",
    "\n",
    "# export column-reduced df to csv as backup\n",
    "coffee_latlong_min.to_csv(\"coffee_latlong_min.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create JSON object to use in data.js file for data.html page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then sent the coffee_latlong_min table to sqlite for storage. We queried the database and returned a JSON object to be used to populate the table on our data.html page. We limited this data to 2015-2019 to show multiple years, and converted to a JSON object. This will be pasted into the data.js file in the static/js folder and prepended with an appropriate variable to be used in the table building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import more dependencies\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"sqlite:///coffee_data.sqlite\")\n",
    "conn = engine.connect()\n",
    "\n",
    "# query db for 2019 arabica production, robusta production & domestic consumption\n",
    "\n",
    "coffee_data = pd.read_sql(\"SELECT Country_Name,Market_Year, Value,Attribute_description, Latitude, Longitude from coffee_latlong_min WHERE Market_year in(2015,2016,2017,2018,2019)\", conn)\n",
    "coffee_data\n",
    "\n",
    "coffee_datajson_file = json.loads(coffee_data.to_json(orient='records'))\n",
    "\n",
    "print(coffee_datajson_file, file=open(\"data1.json\", \"a\"))\n",
    "print(\"Success!\")\n",
    "\n",
    "coffee_data1 = pd.read_sql(\"SELECT Country_Name,Market_Year, Value,Attribute_description, Latitude, Longitude from coffee_latlong_min WHERE Market_year in(2019)\", conn)\n",
    "print(coffee_data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create JSON objects to use in data.js file for Leaflet map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next are creating JSON objects for the three attributes we will be mapping: arabica production, robusta production and domestic consumption. We are working with the df combining coffee data and latitude/longitude coordinates. Each JSON will be pasted into the data.js file in the static/js folder and prepended with an appropriate variable to be used in the map building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit data to 2019 only, remove extraneous columns. do this for each attribute\n",
    "# arabica production\n",
    "arabica_df = coffee_latlong_min.loc[(coffee_latlong_min[\"Attribute_Description\"] == \"Arabica Production\") &\n",
    "                                     (coffee_latlong_min[\"Market_Year\"] == 2019)]\n",
    "arabica_df = arabica_df[[\"Country_Name\", \"Value\", \"Latitude\", \"Longitude\"]]\n",
    "\n",
    "# robusta production\n",
    "robusta_df = coffee_latlong_min.loc[(coffee_latlong_min[\"Attribute_Description\"] == \"Robusta Production\") &\n",
    "                                     (coffee_latlong_min[\"Market_Year\"] == 2019)]\n",
    "robusta_df = robusta_df[[\"Country_Name\", \"Value\", \"Latitude\", \"Longitude\"]]\n",
    "\n",
    "# domestic consumption\n",
    "consump_df = coffee_latlong_min.loc[(coffee_latlong_min[\"Attribute_Description\"] == \"Domestic Consumption\") &\n",
    "                                     (coffee_latlong_min[\"Market_Year\"] == 2019)]\n",
    "consump_df = consump_df[[\"Country_Name\", \"Value\", \"Latitude\", \"Longitude\"]]\n",
    "\n",
    "# convert to JSON\n",
    "arabica_json = json.loads(arabica_df.to_json(orient='records'))\n",
    "robusta_json = json.loads(robusta_df.to_json(orient='records'))\n",
    "consump_json = json.loads(consump_df.to_json(orient='records'))\n",
    "\n",
    "# arabica_json\n",
    "# robusta_json\n",
    "# consump_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a table of all attributes and countries for a single year, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a table of all attributes and countries for a single year, 2019, same as the map year. First we limit the data to 2019 and remove extraneous columns. Then we replace the spaces (\" \") between words with underscores (\"_\") because these values will become keys when we access them in the Javascript files. We then pivot the table to assign the country names as index with each attribute as a column. We then export the cleaned csv to the data folder of our app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit data to 2019 only, for all countries, all attributes\n",
    "coffee_2019 = coffee_latlong_min.loc[coffee_latlong_min[\"Market_Year\"] == 2019]\n",
    "coffee_2019 = coffee_2019[[\"Country_Name\", \"Attribute_Description\", \"Value\"]]\n",
    "\n",
    "# replace spaces between words in Attribute_Description column because they will become column names\n",
    "coffee_2019 [\"Attribute_Description\"] = coffee_2019[\"Attribute_Description\"].str.replace(' ', '_', regex=True)\n",
    "\n",
    "# pivot the df to set country as index with columns for each attribute\n",
    "pivot_2019 = coffee_2019.pivot(index=\"Country_Name\", columns=\"Attribute_Description\", values=\"Value\")\n",
    "pivot_2019\n",
    "\n",
    "# send to csv in the app's data folder\n",
    "pivot_2019.to_csv(\"../static/data/data_2019.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Clean the data for HighCharts Streamgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data will be used to create a streamgraph charting production trends over time for all countries. The data is sorted to display only the desired attributes and then pivoted to align country names as the index and years as the columns, illustrating change over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# query arabica production for all countries and years\n",
    "arabica = coffee_latlong_min.loc[coffee_latlong_min[\"Attribute_Description\"] == \"Arabica Production\"]\n",
    "arabica = arabica[[\"Country_Name\", \"Market_Year\", \"Attribute_Description\", \"Value\"]]\n",
    "arabica_pivot = arabica.pivot(index=\"Market_Year\", columns=\"Country_Name\")[\"Value\"]\n",
    "\n",
    "# query robusta production for all countries and years\n",
    "robusta = coffee_latlong_min.loc[coffee_latlong_min[\"Attribute_Description\"] == \"Robusta Production\"]\n",
    "robusta = robusta[[\"Country_Name\", \"Market_Year\", \"Attribute_Description\", \"Value\"]]\n",
    "robusta_pivot = robusta.pivot(index=\"Market_Year\", columns=\"Country_Name\")[\"Value\"]\n",
    "\n",
    "# query domestic consumption for all countries and years\n",
    "consump = coffee_latlong_min.loc[coffee_latlong_min[\"Attribute_Description\"] == \"Domestic Consumption\"]\n",
    "consump = consump[[\"Country_Name\", \"Market_Year\", \"Attribute_Description\", \"Value\"]]\n",
    "consump_pivot = consump.pivot(index=\"Market_Year\", columns=\"Country_Name\")[\"Value\"]\n",
    "\n",
    "# fill NaNs with 0 to retain as much data as possible\n",
    "arabica_pivot = arabica_pivot.fillna(0)\n",
    "robusta_pivot = robusta_pivot.fillna(0)\n",
    "consump_pivot = consump_pivot.fillna(0)\n",
    "\n",
    "# send to csv in the data folder of the app\n",
    "arabica_pivot.to_csv(\"../static/data/arabica_pivot.csv\")\n",
    "robusta_pivot.to_csv(\"../static/data/robusta_pivot.csv\")\n",
    "consump_pivot.to_csv(\"../static/data/consump_pivot.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
